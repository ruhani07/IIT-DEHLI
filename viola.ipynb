{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0520176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4ae7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load PASCAL VOC dataset\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((24, 24)),\n",
    "    torchvision.transforms.Grayscale(),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170f039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image):\n",
    "    # Convert PIL Image to OpenCV format\n",
    "    cv_image = np.array(image)\n",
    "    cv_image = cv2.cvtColor(cv_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Detect faces using Viola-Jones algorithm\n",
    "    gray_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Convert bounding boxes to (x, y, w, h) format\n",
    "    face_boxes = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_boxes.append((x, y, x + w, y + h))\n",
    "\n",
    "    return face_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aab4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./VOCdevkit\\VOCtrainval_06-Nov-2007.tar\n",
      "Extracting ./VOCdevkit\\VOCtrainval_06-Nov-2007.tar to ./VOCdevkit\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load PASCAL VOC dataset\n",
    "    dataset = torchvision.datasets.VOCDetection(root='./VOCdevkit', year='2007', image_set='trainval',\n",
    "                                                download=True)\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs('viola-images', exist_ok=True)\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        image, target = dataset.__getitem__(i)\n",
    "        image = image.convert('RGB')\n",
    "        face_boxes = detect_faces(image)\n",
    "\n",
    "        # Draw bounding boxes and labels on the image\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        if isinstance(target['annotation']['object'], list):\n",
    "            objects = target['annotation']['object']\n",
    "        else:\n",
    "            objects = [target['annotation']['object']]\n",
    "\n",
    "        # Draw ground truth bounding box\n",
    "        for obj in objects:\n",
    "            name = obj['name']\n",
    "            bbox = obj['bndbox']\n",
    "            x1, y1, x2, y2 = int(bbox['xmin']), int(bbox['ymin']), int(bbox['xmax']), int(bbox['ymax'])\n",
    "            draw.rectangle([(x1, y1), (x2, y2)], outline='green', width=2)\n",
    "            draw.text((x1, y1 - 10), name, fill='green')\n",
    "\n",
    "        # Draw detected face bounding boxes\n",
    "        for (x, y, x2, y2) in face_boxes:\n",
    "            draw.rectangle([(x, y), (x2, y2)], outline='red', width=2)\n",
    "\n",
    "        # Save the image\n",
    "        image.save(f'viola-images/image_{i}.png')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c218b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
